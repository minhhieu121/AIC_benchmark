{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10406138,"sourceType":"datasetVersion","datasetId":6448517},{"sourceId":10412957,"sourceType":"datasetVersion","datasetId":6453427},{"sourceId":10413015,"sourceType":"datasetVersion","datasetId":6453470},{"sourceId":10418058,"sourceType":"datasetVersion","datasetId":6456737}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"begin_index = 0\nend_index = 3\n\n#Count token\nin_token = 0\nout_token = 0\ntimeout_time = 3\n\n# List of API keys\n\n#Key billing TWang\napi_keys = [\n    \"AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\"\n]\n\ngpt_api_keys = []\n\nerror_times = 0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-13T14:28:38.969099Z","iopub.execute_input":"2025-01-13T14:28:38.969506Z","iopub.status.idle":"2025-01-13T14:28:38.975233Z","shell.execute_reply.started":"2025-01-13T14:28:38.969454Z","shell.execute_reply":"2025-01-13T14:28:38.973967Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"#Download packages\n\n#Up-download data\n!pip install gdown google-cloud-storage google-api-python-client google-auth-httplib2 google-auth-oauthlib\n\n#TransnetV2\n!pip install -q ffmpeg-python pillow\n!git clone https://github.com/soCzech/TransNetV2.git\n%cd TransNetV2/inference\n\n#Back-up LLM\n!pip install requests\n\n!pip install tqdm\n\n#Log\n# Cài đặt các thư viện cần thiết\n!pip install google-auth\n!pip install pytz","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T14:28:38.976908Z","iopub.execute_input":"2025-01-13T14:28:38.977399Z","iopub.status.idle":"2025-01-13T14:29:16.258725Z","shell.execute_reply.started":"2025-01-13T14:28:38.977353Z","shell.execute_reply":"2025-01-13T14:29:16.257507Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\nRequirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (2.8.0)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.137.0)\nRequirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.10/dist-packages (0.2.0)\nRequirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (1.2.1)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.5)\nRequirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.27.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (1.34.1)\nRequirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.4.1)\nRequirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.7.2)\nRequirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.22.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (1.3.1)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.65.0)\nRequirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (3.20.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (5.5.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.9)\nRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.6.0)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.1.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.6.1)\nCloning into 'TransNetV2'...\nremote: Enumerating objects: 362, done.\u001b[K\nremote: Counting objects: 100% (84/84), done.\u001b[K\nremote: Compressing objects: 100% (14/14), done.\u001b[K\nremote: Total 362 (delta 70), reused 70 (delta 70), pack-reused 278 (from 1)\u001b[K\nReceiving objects: 100% (362/362), 95.27 KiB | 706.00 KiB/s, done.\nResolving deltas: 100% (210/210), done.\nFiltering content: 100% (3/3), 34.77 MiB | 3.63 MiB/s, done.\n/kaggle/working/TransNetV2/inference\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\nRequirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.27.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (5.5.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\nRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (2024.2)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Import packages\n\n#Up-download data\n# import gdown\nimport math\nimport json\nimport os\nimport time\nfrom google.cloud import storage\nfrom google.oauth2 import service_account\nfrom google.api_core import exceptions as google_exceptions\nfrom googleapiclient.discovery import build\nimport shutil\n\n#TransnetV2\nimport io\nfrom io import BytesIO\nimport cv2\nimport json\nimport glob\nimport ffmpeg\n# import torch\nimport tensorflow as tf\nimport numpy as np\nfrom tqdm import tqdm\nfrom transnetv2 import TransNetV2\nimport subprocess\n\n#Handle features\nimport google.generativeai as genai\nfrom PIL import Image\n\n#Back-up LLM\nimport base64\nimport requests\n\nimport subprocess\nimport os\nimport time\nfrom tqdm import tqdm  # Import tqdm for progress bar\nimport re\nfrom collections import Counter\n\n# Log\nfrom google.oauth2.service_account import Credentials\nfrom googleapiclient.discovery import build\nfrom datetime import datetime\nimport pytz\n\nimport re\nimport csv\nfrom collections import Counter\n\nimport concurrent.futures\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T14:29:16.259983Z","iopub.execute_input":"2025-01-13T14:29:16.260435Z","iopub.status.idle":"2025-01-13T14:29:33.254494Z","shell.execute_reply.started":"2025-01-13T14:29:16.260390Z","shell.execute_reply":"2025-01-13T14:29:33.253260Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def remove_unclear(text):\n    # Sử dụng re.sub để thay thế tất cả cụm \"[unclear]\" bằng chuỗi rỗng\n    return re.sub(r'\\[unclear\\]', '', text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T14:29:33.255650Z","iopub.execute_input":"2025-01-13T14:29:33.256445Z","iopub.status.idle":"2025-01-13T14:29:33.260892Z","shell.execute_reply.started":"2025-01-13T14:29:33.256408Z","shell.execute_reply":"2025-01-13T14:29:33.259806Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def check_hallucination(text, threshold=0.1, repeat_threshold=10):\n    \"\"\"\n    Kiểm tra xem văn bản có chứa sự lặp lại từ hoặc có nhiều mẫu dòng lặp lại hay không.\n\n    Tham số:\n    - text (str): Văn bản để phân tích.\n    - threshold (float): Ngưỡng cho sự lặp lại từ (0.2 tức là 20% lặp lại).\n    - repeat_threshold (int): Số lần lặp lại tối đa cho phép của một mẫu dòng.\n\n    Trả về:\n    - bool: True nếu văn bản có khả năng bị halucinated, False ngược lại.\n    \"\"\"\n    \n    # Kiểm tra kích thước byte của văn bản\n    if len(text.encode('utf-8')) > 9500:\n        return True\n    \n    STOP_WORDS = {\"the\", \"a\", \"an\", \"and\", \"is\", \"in\", \"on\", \"at\",\n                  \"of\", \"for\", \"with\", \"to\", \"from\", \"that\", \"it\",\n                  \"this\", \"by\"}\n\n    # Kiểm tra sự lặp lại của từ\n    words = re.findall(r'\\w+', text.lower())\n    total_words = len(words)\n    if total_words < 200:\n        return False\n\n    word_counts = Counter(words)\n\n    for stop_word in STOP_WORDS:\n        word_counts.pop(stop_word, None)\n\n    if total_words == 0 or not word_counts:\n        return False\n\n    most_common_word, most_common_count = word_counts.most_common(1)[0]\n    repetition_ratio = most_common_count / total_words\n\n    if repetition_ratio > threshold:\n        return True\n\n    # Kiểm tra các mẫu dòng lặp lại\n    lines = text.split('\\n')\n    pattern_counts = Counter()\n\n    for i in range(len(lines) - 1):\n        # Kiểm tra mẫu 2 dòng\n        pattern_2 = tuple(lines[i:i+2])\n        pattern_counts[pattern_2] += 1\n        if pattern_counts[pattern_2] >= repeat_threshold:\n            return True\n\n        if i < len(lines) - 2:\n            # Kiểm tra mẫu 3 dòng\n            pattern_3 = tuple(lines[i:i+3])\n            pattern_counts[pattern_3] += 1\n            if pattern_counts[pattern_3] >= repeat_threshold:\n                return True\n\n    return False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T14:29:33.262248Z","iopub.execute_input":"2025-01-13T14:29:33.262560Z","iopub.status.idle":"2025-01-13T14:29:33.281021Z","shell.execute_reply.started":"2025-01-13T14:29:33.262532Z","shell.execute_reply":"2025-01-13T14:29:33.279961Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def convert_video_gpu(video_path):\n    # Tạo đường dẫn tạm cho file\n    temp_path = f\"{video_path}.temp.mp4\"\n\n    try:\n        # Bắt đầu tính thời gian\n        start_time = time.time()\n\n        # Lấy thông tin về thời lượng video\n        duration = float(subprocess.check_output(['ffprobe', '-v', 'error', '-show_entries', 'format=duration', '-of', 'default=noprint_wrappers=1:nokey=1', video_path]).decode('utf-8'))\n\n        # Tạo đối tượng tqdm\n        pbar = tqdm(total=100, desc=\"Chuyển đổi video (GPU)\", unit=\"%\")\n\n        # Thực hiện chuyển đổi video với các tham số GPU được chỉ định\n        process = subprocess.Popen([\n            'ffmpeg',\n            '-hwaccel', 'cuda',  # Sử dụng CUDA để tăng tốc phần cứng\n            '-i', video_path,\n            '-c:v', 'h264_nvenc',  # Sử dụng mã hóa GPU NVIDIA NVENC cho H.264\n            '-profile:v', 'main',\n            '-level', '3.1',\n            '-preset', 'p4',  # Sử dụng preset của NVENC\n            '-b:v', '2M',  # Bitrate video, tùy chỉnh theo yêu cầu\n            '-c:a', 'aac',\n            '-b:a', '128k',\n            '-movflags', '+faststart',\n            '-progress', 'pipe:1',\n            temp_path\n        ], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n\n        # Cập nhật thanh tiến trình\n        for line in process.stdout:\n            if 'out_time_ms' in line:\n                time_ms = int(line.split('=')[1])\n                progress = min(100, int(100 * time_ms / (duration * 1000000)))\n                pbar.update(progress - pbar.n)\n\n        process.wait()\n        pbar.close()\n\n        # Dừng tính thời gian\n        end_time = time.time()\n\n        # Xóa file gốc\n        os.remove(video_path)\n\n        # Đổi tên file tạm thành tên file gốc\n        os.rename(temp_path, video_path)\n\n        print(f\"Đã chuyển đổi và thay thế video (GPU): {video_path}\")\n        print(f\"Thời gian chuyển đổi (GPU): {end_time - start_time:.2f} giây\")\n\n    except subprocess.CalledProcessError as e:\n        print(f\"Lỗi khi chuyển đổi video: {e}\")\n    except OSError as e:\n        print(f\"Lỗi khi thao tác với file: {e}\")\n    finally:\n        # Đảm bảo xóa file tạm nếu có lỗi xảy ra\n        if os.path.exists(temp_path):\n            os.remove(temp_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T14:29:33.283517Z","iopub.execute_input":"2025-01-13T14:29:33.284009Z","iopub.status.idle":"2025-01-13T14:29:33.302034Z","shell.execute_reply.started":"2025-01-13T14:29:33.283972Z","shell.execute_reply":"2025-01-13T14:29:33.300284Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"prompt_feature_1 = \"\"\"\n    Write a concise description for the middle image of the scene. Use the other images in the scene to gather contextual information. The description should meet the following requirements:\n    - Be between 100 to 150 words.\n    - Clearly state the main action or event happening in the scene.\n    - Mention any prominent objects or people visible in the scene.\n    - Avoid overly detailed analysis of colors, surroundings, or emotions unless necessary for context.\n    - Do not include unnecessary speculation or unrelated information.\n    - Focus on clarity and brevity.\n\"\"\"\n\nprompt_feature_2 = \"\"\"Below is an example of a standard description:\n    The scene is set at a construction site, possibly in Berlin, Germany. The background features a large modern glass building under construction, with scaffolding and construction equipment visible. The building is primarily glass and metal, reflecting sunlight. A section of the building is covered by scaffolding. The ground is paved, appearing to be a road or parking area. The overall lighting suggests it is daytime.\n    The color palette is dominated by blues and grays from the building and sky, interspersed with the yellows and whites of the safety gear worn by the construction workers and the yellow and blue of the police car. The white of the German Red Cross van provides a stark contrast. There are also shades of brown and gray from the construction materials. The overall tone is somewhat subdued due to the overcast sky.\n    Several people are present. There are approximately ten construction workers gathered in a small group, slightly behind a police car. They appear to be wearing high-visibility vests, predominantly yellow and orange, with some wearing helmets. Some also appear to wear other outerwear like jackets. These are primarily neutral or dark colors, including gray, dark blue and black. Their expressions seem serious and possibly concerned. There is a group of at least four uniformed German police officers near the construction workers; some stand casually while others appear to have a more formal discussion with the construction workers.\n    Two vehicles are prominently featured: A white German Red Cross van (marked \"hes Rotes Kreuz\" with a red cross) is parked on the left side of the image. It is a boxy van with sliding doors. A blue and yellow German police car (\"POLIZEI\") is parked in the center-right of the image. This is a station wagon or estate car-style vehicle. The police car looks modern with a sleek design. Both vehicles are significantly larger than the people present.\n    The German Red Cross van is positioned to the left of the image, relatively close to the construction workers and slightly further away from the police car. The police car is central and slightly to the right, facing towards the left of the image. The construction workers are between the police car and the German Red Cross van.\n    The text visible includes \"hes Rotes Kreuz\" on the side of the van, \"POLIZEI\" on the side of the police car. A digital clock display shows \"06:44:13\". The top right corner has a logo that includes \"HTV9HD\". The lower portion of the image shows text in Vietnamese which, according to the transcription is \"Bế mạc Liên hoan phim ngắn TP.HCM năm 2023\" which translates to \"Closing Ceremony of the Short Film Festival, Ho Chi Minh City 2023\". There is also some additional Vietnamese text, \"Địa điểm\", meaning \"Location\", and a timestamp \"10:23/21:06 ứ XXII\"\n    The overall impression is one of a serious incident or accident at the construction site, with emergency responders and construction workers assessing the situation. The solemn expressions and the presence of the police and medical vehicle suggest a potentially significant event.\n    (end of example) \\n\\n\\n\n\"\"\"\n\nprompt_ocr = \"\"\"\nTHINKING STEP BY STEP\n    Extract visible text information from the provided images, adhering strictly to these guidelines:\nTHINKING STEP BY STEP\n1. List only text that is clearly visible and legible in the images.\n2. Do not guess, interpret, or add any information not directly present in the images.\n3. Skip any text that is unclear, blurry, or partially obscured.\n4. Group related text elements (e.g., phrases, names, addresses) into single bullet points.\n5. Use separate bullet points for distinct pieces of information.\n6. Avoid duplicating information, even if it appears multiple times in the images.\n7. For repeating elements (e.g., timestamps, logos), include only one instance.\n8. If uncertain about text, use [unclear] placeholder instead of guessing. DON'T DUPLICATE THE TERM [unclear].\n9. Ignore background noise or irrelevant visual elements.\n10. For multi-image scenarios, compile a single, unified list of unique text elements.\nTHINKING STEP BY STEP\nVerification steps:\n1. Review each extracted text item against the image(s).\n2. Remove any items not directly visible in the images.\n3. Eliminate all duplicates.\n4. Check for and remove any hallucinated or assumed text.\nTHINKING STEP BY STEP\nRemember: Accuracy and uniqueness are crucial. When in doubt, omit rather than speculate.\n\"\"\"\nprompt_summarize = \"\"\"\n    Write a comprehensive summary that describes the entire content of a video based on the detailed descriptions of each scene. The goal is to create a concise yet inclusive description that captures the main ideas and storyline of the video. \n    Ensure that your summary:\n    - Seamlessly integrates the events and key points to create a logical and cohesive narrative.\n    - Excludes superfluous or repetitive details, focusing only on the essential aspects of the video\n    - Emphasizes the progression and flow between scenes to highlight the overall purpose or story being depicted.\n\"\"\"\n\nmodel_name = \"gemini-1.5-flash-002\"\n\nsafety_settings = [\n    {\n        \"category\": \"HARM_CATEGORY_DANGEROUS\",\n        \"threshold\": \"BLOCK_NONE\",\n    },\n    {\n        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n        \"threshold\": \"BLOCK_NONE\",\n    },\n    {\n        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n        \"threshold\": \"BLOCK_NONE\",\n    },\n    {\n        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n        \"threshold\": \"BLOCK_NONE\",\n    },\n    {\n        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n        \"threshold\": \"BLOCK_NONE\",\n    },\n]\n\ndef get_ocr(scene_timestamp, scene_frames_pil, frame_filename):\n    global error_times\n    ocr_txt = \"\"\n    finished = False\n    # index_image = int(len(images)/2)\n    # index_image_file = int(len(image_files)/2)\n    for key in api_keys:\n        try:\n            print(f\"Getting OCR of {scene_timestamp} with key {key}\")\n            genai.configure(api_key=key)\n            model = genai.GenerativeModel(\n                model_name=model_name,\n                generation_config=genai.GenerationConfig(\n                    max_output_tokens=3000  # Set the max output tokens here\n                )\n            )\n            response = model.generate_content([prompt_ocr] + scene_frames_pil, safety_settings = safety_settings)\n\n            response_ocr = response.text\n            if check_hallucination(response_ocr, threshold=0.2):\n                print(\"HALUCINATION FOR OCR!!! ------------------------\")\n                print(response.text)\n                continue\n\n            print(\"OCR has no halucination!\")\n            response_ocr = remove_unclear(response_ocr)\n            print(response_ocr)\n            finished = True\n\n\n\n            print(f\"OCR sucsessfully! \\n\\n\\n\")\n            ocr_txt = \"You can use the following information of text and number appear in the images to help you identify the text appear in the images. Note that most of the words given are in Vietnamese so you must keep the Vietnamese in the description and not translate into English. \\n\" + response_ocr + \" \\n\\n\\n\"\n\n            break  # Exit the loop if successful\n        except Exception as e:\n            print(f\"Getting OCR error with API key {key}: {str(e)}\")\n            error_times += 1\n            if(error_times > 10000):\n                raise Exception(\"------------ SỐ LẦN LỖI QUÁ NHIỀU! CÓ THỂ KEY ĐÃ HẾT HIỆU LỰC!!!!!! ----------\")\n            continue  # Try the next API key\n\n    if not finished:\n        print(\"ERRORRRRR OCR\")\n        \n    return ocr_txt\n\n\n\n\ndef get_feature(video_number, scene_timestamp, scene_frames_pil, frame_filename, description_folder_path):\n    global error_times\n\n    \n\n    #Handle scenes\n    # for scene in sorted(os.listdir(scene_folder_path)):\n    print(f\"************************    {scene_timestamp}    ***************************** \\n\")\n\n    # # Đường dẫn đến thư mục chứa ảnh\n    # image_folder = os.path.join(scene_folder_path, scene)\n\n    # # Lấy danh sách tên file ảnh và sắp xếp\n    # image_files = sorted(os.listdir(image_folder))\n\n    # # Tạo danh sách các đối tượng ảnh\n    # images = [Image.open(os.path.join(image_folder, file)) for file in image_files]\n\n    ocr_txt = get_ocr(scene_timestamp, scene_frames_pil, frame_filename)\n\n\n    # index_image_folder = int(len(image_files)/2)\n\n\n    finished = False\n    for key in api_keys:\n        try:\n            print(f\"Processing folder {scene_timestamp} with key {key}\")\n            genai.configure(api_key=key)\n            model = genai.GenerativeModel(\n                model_name=model_name,\n                generation_config=genai.GenerationConfig(\n                    max_output_tokens=3000  # Set the max output tokens here\n                )\n            )\n            response = model.generate_content([prompt_feature_1 + ocr_txt + prompt_feature_2] + scene_frames_pil, safety_settings = safety_settings)\n\n#             # Save the response text to a file\n#             description_txt = f'response_{frame_filename}.txt'\n#             description_txt_path = os.path.join(description_folder_path, description_txt)\n#             with open(description_txt_path, 'w') as file:\n# #                     print(f\"The response is: \\n {response} \\n\")\n#                 file.write(response.text)\n\n            if check_hallucination(response.text, threshold=0.2):\n                print(\"HALUCINATION FOR FEATURE!!! ------------------------\")\n                print(response.text)\n                continue\n\n            print(\"Feature has no halucination!\")\n\n            # # Thay vì lưu vào file, chúng ta sẽ upload trực tiếp lên Google Cloud Storage\n            # description_content = response.text\n            # description_cloud_path = f\"{video_number}/description/response_{frame_filename}.txt\"\n\n            # description_blob = bucket.blob(description_cloud_path)\n            # description_blob.upload_from_string(description_content, content_type='text/plain')\n\n            # Thay vì lưu vào Google Cloud Storage, lưu vào thư mục Kaggle Working\n            description_content = response.text\n            description_txt = f'response_{frame_filename}.txt'  # Tên file\n            description_txt_path = os.path.join(f\"/kaggle/working/{video_number}/description/\", description_txt)  # Đường dẫn lưu\n            \n            # Mở file và ghi nội dung vào\n            with open(description_txt_path, 'w', encoding='utf-8') as file:\n                file.write(description_content)\n\n            print(f\"Processed and saved response locally at {description_txt_path} for {scene_timestamp}\")\n        \n            # Response tokens count\n            usage_metadata = response.usage_metadata\n            print(f\"Prompt Token Count: {usage_metadata.prompt_token_count}\")\n            print(f\"Candidates Token Count: {usage_metadata.candidates_token_count}\")\n            print(f\"Total Token Count: {usage_metadata.total_token_count} \\n\\n\\n\")\n            finished = True\n            break  # Exit the loop if successful\n        except Exception as e:\n            print(f\"Error with API key {key}: {str(e)}\")\n            error_times += 1\n            if(error_times > 10000):\n                raise Exception(\"------------ SỐ LẦN LỖI QUÁ NHIỀU! CÓ THỂ KEY ĐÃ HẾT HIỆU LỰC!!!!!! ----------\")\n            continue  # Try the next API key\n\n    if not finished:\n        print(\"ERRORRRRR FEATUREEEEEE\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T14:29:33.303637Z","iopub.execute_input":"2025-01-13T14:29:33.304045Z","iopub.status.idle":"2025-01-13T14:29:33.325035Z","shell.execute_reply.started":"2025-01-13T14:29:33.304011Z","shell.execute_reply":"2025-01-13T14:29:33.323891Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        print(e)\n\nprint(tf.__version__)\nprint(\"GPU is\", \"available\" if tf.test.is_built_with_cuda() else \"NOT AVAILABLE\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T14:29:33.326061Z","iopub.execute_input":"2025-01-13T14:29:33.326409Z","iopub.status.idle":"2025-01-13T14:29:33.348077Z","shell.execute_reply.started":"2025-01-13T14:29:33.326369Z","shell.execute_reply":"2025-01-13T14:29:33.346705Z"}},"outputs":[{"name":"stdout","text":"Num GPUs Available:  0\n2.17.0\nGPU is available\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip install decord\n!pip install av","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T14:29:33.349207Z","iopub.execute_input":"2025-01-13T14:29:33.349595Z","iopub.status.idle":"2025-01-13T14:29:43.929360Z","shell.execute_reply.started":"2025-01-13T14:29:33.349553Z","shell.execute_reply":"2025-01-13T14:29:43.928276Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting decord\n  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from decord) (1.26.4)\nDownloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: decord\nSuccessfully installed decord-0.6.0\nCollecting av\n  Downloading av-14.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\nDownloading av-14.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.0/33.0 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: av\nSuccessfully installed av-14.0.1\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from concurrent.futures import ThreadPoolExecutor\n\n\nmodel = TransNetV2()\n\ndef format_time(milliseconds):\n    seconds = milliseconds // 1000\n    remaining_ms = milliseconds % 1000\n    return f\"{seconds:05}{remaining_ms:03}\"\n\ndef process_scene(video_number, scene_timestamp, scene_frames_pil, frame_filename, scene_folder_path, description_folder_path):\n    # Gọi hàm get_feature (giữ nguyên logic cũ)\n    # Lấy middle frame\n    middle_frame = scene_frames_pil[len(scene_frames_pil) // 2]\n\n    # Đường dẫn lưu middle frame trong scene folder\n    middle_frame_path = os.path.join(scene_folder_path, frame_filename)\n\n    # Lưu middle frame vào scene folder\n    middle_frame.save(middle_frame_path)\n    \n    get_feature(video_number, scene_timestamp, scene_frames_pil, frame_filename, description_folder_path)\n\ndef extract_and_save_frames(video_path, scenes, scene_folder_path, description_folder_path):\n    video_cap = cv2.VideoCapture(video_path)\n    fps = video_cap.get(cv2.CAP_PROP_FPS)\n    fps_str = \"{:.2f}\".format(round(fps, 2)).replace('.', '')\n    video_number = os.path.splitext(os.path.basename(video_path))[0].split('.')[-1]\n\n\n\n    for scene_idx, (start_frame, end_frame) in enumerate(scenes):\n        start_time = format_time(int(start_frame * 1000 / fps))\n        end_time = format_time(int(end_frame * 1000 / fps))\n\n        scene_timestamp = f\"{video_number}_scene_{scene_idx:04}_{start_time}_{end_time}\"\n\n        key_frames = [start_frame + (end_frame - start_frame) * i // 25 for i in range(26)]\n        key_frames = sorted(set(key_frames))\n\n        scene_frames_pil = []\n        valid_frame_indexs = []\n\n        for frame_idx in key_frames:\n            video_cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n            ret, frame = video_cap.read()\n            if not ret:\n                break\n\n            valid_frame_indexs.append(frame_idx)\n            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n            pil_image = Image.fromarray(frame_rgb)\n            scene_frames_pil.append(pil_image)\n\n        middle_frame_index = valid_frame_indexs[len(valid_frame_indexs) // 2]\n        frame_time = format_time(int(middle_frame_index * 1000 / fps))\n        frame_filename = f\"{video_number}_frame_{scene_idx:04}_{frame_time}_{middle_frame_index}_{fps_str}.png\"\n\n        process_scene(video_number, scene_timestamp, scene_frames_pil, frame_filename, scene_folder_path, description_folder_path)\n    \n    video_cap.release()\n\n\ndef get_scene(video_path, scene_folder_path, description_folder_path):\n    #TO DO\n    #Gắn cái path vid vô đây là xong\n    # Đọc video và chuyển thành tensor\n\n    _, single_frame_predictions, _ = model.predict_video(video_path)\n    scenes = model.predictions_to_scenes(single_frame_predictions)\n    extract_and_save_frames(video_path, scenes, scene_folder_path, description_folder_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T14:29:43.930767Z","iopub.execute_input":"2025-01-13T14:29:43.931137Z","iopub.status.idle":"2025-01-13T14:29:49.729796Z","shell.execute_reply.started":"2025-01-13T14:29:43.931098Z","shell.execute_reply":"2025-01-13T14:29:49.728980Z"}},"outputs":[{"name":"stdout","text":"[TransNetV2] Using weights from /kaggle/working/TransNetV2/inference/transnetv2-weights/.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def temporal_refinement_gemini(full_video_context):\n    for key in api_keys:\n        genai.configure(api_key=key)    \n        model = genai.GenerativeModel(\n            model_name=model_name,\n            generation_config=genai.GenerationConfig(\n                max_output_tokens=3000  # Set the max output tokens here\n            )\n        )\n\n        response = model.generate_content(full_video_context + prompt_summarize, safety_settings = safety_settings)\n\n        return response.text\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T14:29:49.730694Z","iopub.execute_input":"2025-01-13T14:29:49.730985Z","iopub.status.idle":"2025-01-13T14:29:49.736230Z","shell.execute_reply.started":"2025-01-13T14:29:49.730956Z","shell.execute_reply":"2025-01-13T14:29:49.735152Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def get_video_description(description_folder_path):\n    #GET FULL SCENE DESCRIPTION    \n    full_video_context = ''\n    descriptions = os.listdir(description_folder_path)\n    for idx, description in enumerate(descriptions):\n        with open(f'{description_folder_path}/{description}', 'r') as f:\n            video_description = f.read()\n            full_video_context += f'**SCENE {idx}**\\n'\n            full_video_context += video_description\n\n    refined_context = temporal_refinement_gemini(full_video_context)\n    return refined_context","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T14:29:49.737256Z","iopub.execute_input":"2025-01-13T14:29:49.737572Z","iopub.status.idle":"2025-01-13T14:29:49.757489Z","shell.execute_reply.started":"2025-01-13T14:29:49.737534Z","shell.execute_reply":"2025-01-13T14:29:49.756501Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Thư mục đích trong Kaggle\noutput_dir = \"/kaggle/working/\"\noutput_txt_dir = \"/kaggle/working/output/\"\nos.makedirs(output_dir, exist_ok=True)\nos.makedirs(output_txt_dir, exist_ok=True)\n\n# Tải và xử lý từng file mp4\nwith open('/kaggle/input/videotest/video_id.json', 'r') as file:\n    video_list = json.load(file)\n\nfor vid_index in range(begin_index, end_index + 1):\n    video_name = video_list[vid_index]\n\n    try:\n        # Xử lý video\n        print(f\"Processing: {video_name}\")\n        \n        # Tạo thư mục scene và description\n        os.makedirs(f\"/kaggle/working/{video_name}/scene\", exist_ok=True)\n        os.makedirs(f\"/kaggle/working/{video_name}/description\", exist_ok=True)\n\n        video_path = f\"/kaggle/input/msrvtt/MSRVTT/videos/all/{video_name}.mp4\"\n        scene_folder_path = f\"/kaggle/working/{video_name}/scene\"\n        description_folder_path = f\"/kaggle/working/{video_name}/description\"\n\n        # convert_video_gpu(video_path)\n\n        with tf.device('/GPU:0'):\n            get_scene(video_path, scene_folder_path, description_folder_path)\n\n        # Lấy và lưu video_description\n        video_description = get_video_description(description_folder_path)\n        \n        # Lưu video_description vào thư mục của từng video\n        with open(f'{output_dir}/{video_name}/{video_name}.txt', 'w') as f:\n            f.write(video_description)\n\n        # Lưu video_description vào file text trong thư mục 'output'\n        output_file_path = f'{output_txt_dir}/{video_name}.txt'\n        with open(output_file_path, 'w') as f:\n            f.write(video_description)\n\n        print(f\"Process Video Successfully!\")\n\n    except Exception as e:\n        print(f\"Lỗi khi xử lý {video_name}: {e}\")\n        print(\"Bỏ qua file này và tiếp tục với file tiếp theo...\")\n        continue\n\n    print(f\"Hoàn thành xử lý: {video_name}\\n\")\n\n\n\n\n\n# import os\n# import json\n# import time\n# import tensorflow as tf\n# from concurrent.futures import ThreadPoolExecutor\n\n# # Thư mục đích trong Kaggle\n# output_dir = \"/kaggle/working/\"\n# output_txt_dir = \"/kaggle/working/output/\"\n# os.makedirs(output_dir, exist_ok=True)\n# os.makedirs(output_txt_dir, exist_ok=True)\n\n# # Tải và xử lý từng file mp4\n# with open('/kaggle/input/videotest/video_id.json', 'r') as file:\n#     video_list = json.load(file)\n\n# def process_video(vid_index):\n#     \"\"\"Hàm xử lý từng video\"\"\"\n#     video_name = video_list[vid_index]\n#     try:\n#         print(f\"Processing: {video_name}\")\n        \n#         # Tạo thư mục scene và description\n#         os.makedirs(f\"/kaggle/working/{video_name}/scene\", exist_ok=True)\n#         os.makedirs(f\"/kaggle/working/{video_name}/description\", exist_ok=True)\n\n#         video_path = f\"/kaggle/input/msrvtt/MSRVTT/videos/all/{video_name}.mp4\"\n#         scene_folder_path = f\"/kaggle/working/{video_name}/scene\"\n#         description_folder_path = f\"/kaggle/working/{video_name}/description\"\n\n#         # convert_video_gpu(video_path)\n\n#         with tf.device('/GPU:0'):\n#             get_scene(video_path, scene_folder_path, description_folder_path)\n\n#         # Lấy và lưu video_description\n#         video_description = get_video_description(description_folder_path)\n        \n#         # Lưu video_description vào thư mục của từng video\n#         with open(f'{output_dir}/{video_name}/{video_name}.txt', 'w') as f:\n#             f.write(video_description)\n\n#         # Lưu video_description vào file text trong thư mục 'output'\n#         output_file_path = f'{output_txt_dir}/{video_name}.txt'\n#         with open(output_file_path, 'w') as f:\n#             f.write(video_description)\n\n#         print(f\"Process Video Successfully for {video_name}!\")\n#         time.sleep(timeout_time)\n\n#     except Exception as e:\n#         print(f\"Lỗi khi xử lý {video_name}: {e}\")\n#         print(\"Bỏ qua file này và tiếp tục với file tiếp theo...\")\n\n# # Cấu hình số lượng worker\n# num_workers = 50\n# begin_index = 0  # Ví dụ: bắt đầu từ index 0\n# end_index = len(video_list) - 1  # Đến cuối danh sách\n\n# # Khởi tạo ThreadPoolExecutor\n# with ThreadPoolExecutor(max_workers=num_workers) as executor:\n#     # Gửi các công việc vào executor\n#     executor.map(process_video, range(begin_index, end_index + 1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T14:29:49.758497Z","iopub.execute_input":"2025-01-13T14:29:49.758873Z","iopub.status.idle":"2025-01-13T14:32:06.413972Z","shell.execute_reply.started":"2025-01-13T14:29:49.758833Z","shell.execute_reply":"2025-01-13T14:32:06.412804Z"}},"outputs":[{"name":"stdout","text":"Processing: video7020\n[TransNetV2] Extracting frames from /kaggle/input/msrvtt/MSRVTT/videos/all/video7020.mp4\n[TransNetV2] Processing video frames 330/330\n************************    video7020_scene_0000_00000000_00003003    ***************************** \n\nGetting OCR of video7020_scene_0000_00000000_00003003 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nOCR has no halucination!\nThere is no visible text in the provided images.\nOCR sucsessfully! \n\n\n\nProcessing folder video7020_scene_0000_00000000_00003003 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nFeature has no halucination!\nProcessed and saved response locally at /kaggle/working/video7020/description/response_video7020_frame_0000_00001534_46_2997.png.txt for video7020_scene_0000_00000000_00003003\nPrompt Token Count: 7552\nCandidates Token Count: 123\nTotal Token Count: 7675 \n\n\n\n************************    video7020_scene_0001_00003036_00006139    ***************************** \n\nGetting OCR of video7020_scene_0001_00003036_00006139 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nOCR has no halucination!\nThere is no visible text in the provided images.\nOCR sucsessfully! \n\n\n\nProcessing folder video7020_scene_0001_00003036_00006139 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nFeature has no halucination!\nProcessed and saved response locally at /kaggle/working/video7020/description/response_video7020_frame_0001_00004637_139_2997.png.txt for video7020_scene_0001_00003036_00006139\nPrompt Token Count: 7552\nCandidates Token Count: 126\nTotal Token Count: 7678 \n\n\n\n************************    video7020_scene_0002_00006206_00007440    ***************************** \n\nGetting OCR of video7020_scene_0002_00006206_00007440 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nOCR has no halucination!\nThere is no visible text in the provided images.\nOCR sucsessfully! \n\n\n\nProcessing folder video7020_scene_0002_00006206_00007440 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nFeature has no halucination!\nProcessed and saved response locally at /kaggle/working/video7020/description/response_video7020_frame_0002_00006840_205_2997.png.txt for video7020_scene_0002_00006206_00007440\nPrompt Token Count: 7552\nCandidates Token Count: 111\nTotal Token Count: 7663 \n\n\n\n************************    video7020_scene_0003_00007474_00009075    ***************************** \n\nGetting OCR of video7020_scene_0003_00007474_00009075 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nOCR has no halucination!\nThere is no visible text in the provided images.\nOCR sucsessfully! \n\n\n\nProcessing folder video7020_scene_0003_00007474_00009075 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nFeature has no halucination!\nProcessed and saved response locally at /kaggle/working/video7020/description/response_video7020_frame_0003_00008274_248_2997.png.txt for video7020_scene_0003_00007474_00009075\nPrompt Token Count: 7552\nCandidates Token Count: 116\nTotal Token Count: 7668 \n\n\n\n************************    video7020_scene_0004_00009109_00010977    ***************************** \n\nGetting OCR of video7020_scene_0004_00009109_00010977 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nOCR has no halucination!\nHere's a list of the visible text from the provided images, following all guidelines:\n\n* Wilton\n\n\nOCR sucsessfully! \n\n\n\nProcessing folder video7020_scene_0004_00009109_00010977 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nFeature has no halucination!\nProcessed and saved response locally at /kaggle/working/video7020/description/response_video7020_frame_0004_00010076_302_2997.png.txt for video7020_scene_0004_00009109_00010977\nPrompt Token Count: 7564\nCandidates Token Count: 95\nTotal Token Count: 7659 \n\n\n\nProcess Video Successfully!\nHoàn thành xử lý: video7020\n\nProcessing: video7021\n[TransNetV2] Extracting frames from /kaggle/input/msrvtt/MSRVTT/videos/all/video7021.mp4\n[TransNetV2] Processing video frames 288/288\n************************    video7021_scene_0000_00000000_00000291    ***************************** \n\nGetting OCR of video7021_scene_0000_00000000_00000291 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nOCR has no halucination!\nThere is no visible text in the provided images.\n\nOCR sucsessfully! \n\n\n\nProcessing folder video7021_scene_0000_00000000_00000291 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nFeature has no halucination!\nProcessed and saved response locally at /kaggle/working/video7021/description/response_video7021_frame_0000_00000166_4_2400.png.txt for video7021_scene_0000_00000000_00000291\nPrompt Token Count: 2909\nCandidates Token Count: 100\nTotal Token Count: 3009 \n\n\n\n************************    video7021_scene_0001_00000333_00009125    ***************************** \n\nGetting OCR of video7021_scene_0001_00000333_00009125 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nOCR has no halucination!\nHere's a list of the visible text from the provided images, following all instructions:\n\n* 25 (Number on a baseball player's jersey)\n* 3 (Number on a baseball player's jersey)\nOCR sucsessfully! \n\n\n\nProcessing folder video7021_scene_0001_00000333_00009125 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nFeature has no halucination!\nProcessed and saved response locally at /kaggle/working/video7021/description/response_video7021_frame_0001_00004875_117_2400.png.txt for video7021_scene_0001_00000333_00009125\nPrompt Token Count: 7589\nCandidates Token Count: 140\nTotal Token Count: 7729 \n\n\n\n************************    video7021_scene_0002_00009166_00011875    ***************************** \n\nGetting OCR of video7021_scene_0002_00009166_00011875 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nOCR has no halucination!\nThere is no visible text in the provided images.  Therefore, the list of extracted text is empty.\n\nOCR sucsessfully! \n\n\n\nProcessing folder video7021_scene_0002_00009166_00011875 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nFeature has no halucination!\nProcessed and saved response locally at /kaggle/working/video7021/description/response_video7021_frame_0002_00010541_253_2400.png.txt for video7021_scene_0002_00009166_00011875\nPrompt Token Count: 7564\nCandidates Token Count: 142\nTotal Token Count: 7706 \n\n\n\n************************    video7021_scene_0003_00011916_00011958    ***************************** \n\nGetting OCR of video7021_scene_0003_00011916_00011958 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nOCR has no halucination!\nThere is no visible text in the provided images.\n\nOCR sucsessfully! \n\n\n\nProcessing folder video7021_scene_0003_00011916_00011958 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nFeature has no halucination!\nProcessed and saved response locally at /kaggle/working/video7021/description/response_video7021_frame_0003_00011958_287_2400.png.txt for video7021_scene_0003_00011916_00011958\nPrompt Token Count: 1361\nCandidates Token Count: 112\nTotal Token Count: 1473 \n\n\n\nProcess Video Successfully!\nHoàn thành xử lý: video7021\n\nProcessing: video7024\n[TransNetV2] Extracting frames from /kaggle/input/msrvtt/MSRVTT/videos/all/video7024.mp4\n[TransNetV2] Processing video frames 480/480\n************************    video7024_scene_0000_00000000_00000734    ***************************** \n\nGetting OCR of video7024_scene_0000_00000000_00000734 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nOCR has no halucination!\nThere is no visible text in the provided images.\nOCR sucsessfully! \n\n\n\nProcessing folder video7024_scene_0000_00000000_00000734 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nFeature has no halucination!\nProcessed and saved response locally at /kaggle/working/video7024/description/response_video7024_frame_0000_00000367_11_2997.png.txt for video7024_scene_0000_00000000_00000734\nPrompt Token Count: 6778\nCandidates Token Count: 110\nTotal Token Count: 6888 \n\n\n\n************************    video7024_scene_0001_00000767_00005205    ***************************** \n\nGetting OCR of video7024_scene_0001_00000767_00005205 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nOCR has no halucination!\nHere's a list of the visible text from the provided images, following all instructions:\n\n* LOVE\n* WASH\nOCR sucsessfully! \n\n\n\nProcessing folder video7024_scene_0001_00000767_00005205 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nFeature has no halucination!\nProcessed and saved response locally at /kaggle/working/video7024/description/response_video7024_frame_0001_00003069_92_2997.png.txt for video7024_scene_0001_00000767_00005205\nPrompt Token Count: 7566\nCandidates Token Count: 111\nTotal Token Count: 7677 \n\n\n\n************************    video7024_scene_0002_00005238_00010210    ***************************** \n\nGetting OCR of video7024_scene_0002_00005238_00010210 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nOCR has no halucination!\nThere is no visible text in the provided images.\nOCR sucsessfully! \n\n\n\nProcessing folder video7024_scene_0002_00005238_00010210 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nFeature has no halucination!\nProcessed and saved response locally at /kaggle/working/video7024/description/response_video7024_frame_0002_00007807_234_2997.png.txt for video7024_scene_0002_00005238_00010210\nPrompt Token Count: 7552\nCandidates Token Count: 118\nTotal Token Count: 7670 \n\n\n\n************************    video7024_scene_0003_00010243_00015982    ***************************** \n\nGetting OCR of video7024_scene_0003_00010243_00015982 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nOCR has no halucination!\nThere is no visible text in the provided images.\nOCR sucsessfully! \n\n\n\nProcessing folder video7024_scene_0003_00010243_00015982 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nFeature has no halucination!\nProcessed and saved response locally at /kaggle/working/video7024/description/response_video7024_frame_0003_00013213_396_2997.png.txt for video7024_scene_0003_00010243_00015982\nPrompt Token Count: 7552\nCandidates Token Count: 117\nTotal Token Count: 7669 \n\n\n\nProcess Video Successfully!\nHoàn thành xử lý: video7024\n\nProcessing: video7025\n[TransNetV2] Extracting frames from /kaggle/input/msrvtt/MSRVTT/videos/all/video7025.mp4\n[TransNetV2] Processing video frames 336/336\n************************    video7025_scene_0000_00000000_00001418    ***************************** \n\nGetting OCR of video7025_scene_0000_00000000_00001418 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/proto/marshal/rules/enums.py:37: UserWarning: Unrecognized BlockReason enum value: 4\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Getting OCR error with API key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ: Invalid operation: The `response.parts` quick accessor requires a single candidate, but none were returned. Please check the `response.prompt_feedback` to determine if the prompt was blocked.\nERRORRRRR OCR\nProcessing folder video7025_scene_0000_00000000_00001418 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nError with API key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ: Invalid operation: The `response.parts` quick accessor requires a single candidate, but none were returned. Please check the `response.prompt_feedback` to determine if the prompt was blocked.\nERRORRRRR FEATUREEEEEE\n************************    video7025_scene_0001_00001459_00004295    ***************************** \n\nGetting OCR of video7025_scene_0001_00001459_00004295 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nOCR has no halucination!\nThere is no visible text in the provided images.\n\nOCR sucsessfully! \n\n\n\nProcessing folder video7025_scene_0001_00001459_00004295 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nFeature has no halucination!\nProcessed and saved response locally at /kaggle/working/video7025/description/response_video7025_frame_0001_00002919_70_2398.png.txt for video7025_scene_0001_00001459_00004295\nPrompt Token Count: 7553\nCandidates Token Count: 105\nTotal Token Count: 7658 \n\n\n\n************************    video7025_scene_0002_00004337_00007549    ***************************** \n\nGetting OCR of video7025_scene_0002_00004337_00007549 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nOCR has no halucination!\nThere is no visible text in the provided images.\nOCR sucsessfully! \n\n\n\nProcessing folder video7025_scene_0002_00004337_00007549 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nFeature has no halucination!\nProcessed and saved response locally at /kaggle/working/video7025/description/response_video7025_frame_0002_00006006_144_2398.png.txt for video7025_scene_0002_00004337_00007549\nPrompt Token Count: 7552\nCandidates Token Count: 109\nTotal Token Count: 7661 \n\n\n\n************************    video7025_scene_0003_00007590_00013972    ***************************** \n\nGetting OCR of video7025_scene_0003_00007590_00013972 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nOCR has no halucination!\nThere is no visible text in the provided images.\n\nOCR sucsessfully! \n\n\n\nProcessing folder video7025_scene_0003_00007590_00013972 with key AIzaSyAOoStpA0Gg7U1GzCVv4cqfL0Ij_YRIWpQ\nFeature has no halucination!\nProcessed and saved response locally at /kaggle/working/video7025/description/response_video7025_frame_0003_00010885_261_2398.png.txt for video7025_scene_0003_00007590_00013972\nPrompt Token Count: 7553\nCandidates Token Count: 144\nTotal Token Count: 7697 \n\n\n\nProcess Video Successfully!\nHoàn thành xử lý: video7025\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import shutil\n\n# Đường dẫn thư mục output và tệp zip\noutput_txt_dir = \"/kaggle/working/video7021/scene\"\nzip_file_path = \"/kaggle/working/\"\n\ntry:\n    # Nén thư mục output thành tệp zip\n    shutil.make_archive(output_txt_dir.rstrip('/'), 'zip', output_txt_dir)\n    print(f\"Thư mục output đã được nén thành: {zip_file_path}\")\nexcept Exception as e:\n    print(f\"Lỗi khi nén thư mục output: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T14:43:53.208292Z","iopub.execute_input":"2025-01-13T14:43:53.208752Z","iopub.status.idle":"2025-01-13T14:43:53.234264Z","shell.execute_reply.started":"2025-01-13T14:43:53.208716Z","shell.execute_reply":"2025-01-13T14:43:53.233193Z"}},"outputs":[{"name":"stdout","text":"Thư mục output đã được nén thành: /kaggle/working/\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}